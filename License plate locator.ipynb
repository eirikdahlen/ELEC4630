{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - License plate locator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "Automatically locate the number plate in the following image. (Available in numberplates2020.zip from Blackboard). You may try a 2D cross-correlation with a template matching the plate border, but you will probably need to ‘chamfer’ the template by convolving with a Gaussian or some other blurring function. \n",
    "You’ll also need a good edge detector such as the Canny Edge detector. Test your method on the other example car images from numberplates2020.zip and show the results. \n",
    "\n",
    "In your report discuss methods used, problems encountered, performance, and possible solutions. Comment on the problems encountered in plate extraction and the difficulties in designing a general plate extractor.\n",
    "\n",
    "##### Marking Scheme\n",
    "* Coding of a solution to locate one number plate, description and explanation of method, related images and graphs (5 marks)\n",
    "* Testing method on all other number plates, modification of method as required, showing related images with detection overlay (2 marks)\n",
    "* Comment on the many challenges to number plate detection including lighting, different shaped plates, different coloured plates, perspective distortion, angle of rotation, and so on and suggest possible solutions. (3 marks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to algorithm\n",
    "\n",
    "Firstly I'll introduce the different methods I've worked with and the algorithm flow step by step.\n",
    "Then I'll run the algorithm to show the results for car 1. I will discuss why some methods were chosen and some abandoned for this case. Next I'll show how the algorithm works for the rest of the images, and discuss why the results are variyng.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Imports\n",
    "\n",
    "I will import the necessary libraries and need a function to import the image I want to process. \n",
    "I'm using the [OpenCV](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_table_of_contents_imgproc/py_table_of_contents_imgproc.html) library for Python to do image processing. Numpy is needed for mathematical operations and pyplot to plot results.\n",
    "\n",
    "The image is imported in colors so I can use the orignal for drawing the countours in the later steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def import_image(image):\n",
    "    \"\"\"Imports the given image in colors\"\"\"\n",
    "    return cv2.imread(image, cv2.IMREAD_COLOR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Preprocessing\n",
    "\n",
    "Further we introduce different ways of preprocessing the images. \n",
    "\n",
    "#### Grayscale\n",
    "First, you would like to convert your image to grayscale - this is done to reduce information in each pixel, and we keep it to only two dimensions.\n",
    "\n",
    "#### Thresholding\n",
    "Thresholding helps classifying pixels in the images, given the threshold value. There are several types of thresholds available, and I did try out both simple thresholding, adaptive thresholding and Otsu thresholding. \n",
    "\n",
    "#### Blur\n",
    "Bluring is used to remove noise from the image and smooth things out, using a low-pass filter kernel. The kernel size can be chosen. There are many options for different blur methods, but Gaussian is used in this case.\n",
    "\n",
    "#### Resizing and cropping\n",
    "Images may come in varying sizes and therefore it would be nice to change the size of the images I'm processing.\n",
    "The crop methods divides the image into 10 both horizontally and vertically, and crop the image removing top 2/10 and bottom 1/10 of the height, and 1/10 of both left and right side from the width.\n",
    "\n",
    "#### Morphology\n",
    "Methods used for extracting image components that are useful in the representation and description of region shape. I've implemented methods for erosion, dilation, opening and closing.\n",
    "\n",
    "#### Remove shadows\n",
    "A function to remove shadows from the images, which includes using many of the already implemented methods.\n",
    "This method include:\n",
    "* Dilate the image, in order to get rid of the text.\n",
    "* Blur the image, this gives a good background image that contains shadows.\n",
    "* Calculate the difference between the original and the background. \n",
    "* Normalize the image, so that we use the full dynamic range.\n",
    "* Threshold the image using Truncated threshold, and then normalize again\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscaled(image):\n",
    "    \"\"\"Turns an image into a grayscaled image\"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def threshold(image, thresh=170, maxval=255, threshold_type=cv2.THRESH_TOZERO):\n",
    "    ret, image_thresh = cv2.threshold(image, thresh, maxval, threshold_type)\n",
    "    return image_thresh\n",
    "\n",
    "def adaptive_threshold(image, maxval=255, adaptive_threshold_type=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, threshold_type=cv2.THRESH_TOZERO, block_size=11, c=2):\n",
    "    return cv2.adaptiveThreshold(image, maxval, adaptive_threshold_type, threshold_type, block_size, c)\n",
    "\n",
    "def blur(image, kernel_tuple=(5,5)):\n",
    "    return cv2.GaussianBlur(image, kernel_tuple, 0)\n",
    "\n",
    "def resize(image, size=None, scale_x=2, scale_y=2, interpolation=cv2.INTER_LINEAR):\n",
    "    return cv2.resize(src=image, dsize=size, fx=scale_x, fy=scale_y, interpolation=interpolation)\n",
    "    \n",
    "def crop(image):\n",
    "    image_tuple = image.shape\n",
    "    height, width = image_tuple[0], image_tuple[1]\n",
    "    return image[height*2//10 : height*9//10, width//10 : width*9//10]\n",
    "\n",
    "def morph_opening(image, kernel_size=(5,5)):\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "def morph_closing(image, kernel_size=(5,5)):\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "def remove_shadows(image):\n",
    "    dilated_img = cv2.dilate(image, np.ones((5,5), np.uint8)) \n",
    "    cv2.imshow(\"dil\", dilated_img)\n",
    "    \n",
    "    blurred_img = blur(dilated_img, (3,3))\n",
    "    cv2.imshow(\"blur\", blurred_img)\n",
    "    \n",
    "    diff_img = 255 - cv2.absdiff(image, blurred_img)\n",
    "    cv2.imshow(\"diff\", diff_img)\n",
    "    \n",
    "    norm_img = diff_img.copy() \n",
    "    cv2.normalize(diff_img, norm_img, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "    cv2.imshow(\"norm\", norm_img)\n",
    "    \n",
    "    thr_img = threshold(norm_img, 230, 0, cv2.THRESH_TRUNC)\n",
    "    cv2.imshow(\"thresh\", thr_img)\n",
    "    cv2.normalize(thr_img, thr_img, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "    cv2.imshow(\"normed_thresh\", thr_img)\n",
    "    cv2.waitKey()\n",
    "    return thr_img\n",
    "\n",
    "def dilation(image, kernel_size=(5,5), iterations = 1):\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations)\n",
    "\n",
    "def erosion(image, kernel_size=(5,5), iterations = 1):\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Edge detector\n",
    "\n",
    "Using an edge detector would be useful for finding the egdes of the license plates. Here, Canny is used with the option to set min and max values; those who lie between these two thresholds are classified edges or non-edges based on their connectivity. Canny is used because it automatically removes noises first, unlike Sobel and Laplacian. \n",
    "The Canny edge detector in OpenCV is using 5x5 Gaussian filter to reduce noise and non-maximum suppression to remove unwanted pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def edge_detector(image, minval=100, maxval=150):\n",
    "    return cv2.Canny(image, minval, maxval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Finding the license plate\n",
    "\n",
    "After the preprocessing is done, we can draw countours to identify the license plates.\n",
    "\n",
    "The find_countours method takes the preprocessed image and the original image and find countours in the image. This is represented as a list. Then I draw all the possible countours in the image (in green).\n",
    "\n",
    "The mehtod find_license_plate is then used. The list is here sorted on area size, and only the top n entries are included. Every countour calculates an approximation. It approximates a contour shape to another shape with less number of vertices depending upon the precision I specify, which is the epsilon. An epsilon of 0.05 indicates 5% of the arc length. \n",
    "\n",
    "I iterate through all the top n countours and check one by one if the contour contains four corners, as that would most likely be the number plate. \n",
    "\n",
    "If there is four corners, it is checked agains several other methods.\n",
    "Some countours marked the whole image as a big box, which gave a perfect square. To avoid this from being the \"best\" rectangle, countour_is_whole_image is used.\n",
    "Some countours had four corners, but was more vertical than horizontal. Given that all license plates are horisontal rectangles, we could also exclude these countours using is_vertical_countour which calculates of the vertical lines are longer than the horizontal ones.\n",
    "Some circular approximations where also marked with four corners (strange enough), and to avoid this I calculated the difference in height and width to be sure I did not mark a circle as the license plate.\n",
    "\n",
    "I also included a method for convex hull. The convex hull function checks a curve for convexity defects and corrects it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countour_is_whole_image(countour, image):\n",
    "    left_upper_corner_width = countour[0][0][0]\n",
    "    left_upper_corner_height = countour[0][0][1]\n",
    "    right_lower_corner_width = countour[2][0][0]\n",
    "    right_lower_corner_height = countour[2][0][1]\n",
    "    if left_upper_corner_width < 20 \\\n",
    "        and left_upper_corner_height < 20 \\\n",
    "        and image.shape[0] - right_lower_corner_height < 20 \\\n",
    "        and image.shape[1] - right_lower_corner_width < 20:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_vertical_countour(countour):\n",
    "    left_upper_corner_width = countour[0][0][0]\n",
    "    right_upper_corner_width = countour[3][0][0]\n",
    "    horizontally = abs(right_upper_corner_width - left_upper_corner_width)\n",
    "    \n",
    "    left_upper_corner_height = countour[0][0][1]\n",
    "    left_lower_corner_height = countour[3][0][1]\n",
    "    vertically = abs(left_lower_corner_height - left_upper_corner_height)\n",
    "    if vertically > horizontally:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_rectangle(countour):\n",
    "    \n",
    "    left_upper_corner_height = countour[0][0][0]\n",
    "    right_upper_corner_height = countour[1][0][0]\n",
    "    left_upper_corner_width = countour[0][0][1]\n",
    "    left_lower_corner_width = countour[3][0][1]\n",
    "    \n",
    "    diff_height = abs(right_upper_corner_height - left_upper_corner_height)\n",
    "    diff_width = abs(left_lower_corner_width - left_upper_corner_width)\n",
    "    print(diff_height, diff_width)\n",
    "    if diff_height < 20 and diff_width < 20:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def convex(cnt):\n",
    "    return cv2.convexHull(cnt)\n",
    "\n",
    "def find_license_plate(image, countours, image_name, top_n=20):\n",
    "    countour = sorted(countours, key = cv2.contourArea, reverse = True)[:top_n]\n",
    "    screen_countour = None #store the number plate contour\n",
    "    copied_image = image.copy()\n",
    "    \n",
    "    for c in countour:\n",
    "        copy = copied_image.copy()\n",
    "        copy2 = copy.copy()\n",
    "        copy3 = copy.copy()\n",
    "        cv2.drawContours(copy, [c], -1, (0, 255, 0), 3)\n",
    "        \n",
    "        #con = convex(c)\n",
    "        #cv2.drawContours(copy2, [con], -1, (0, 255, 0), 3)\n",
    "        #cv2.waitKey()\n",
    "        \n",
    "        perimeter = cv2.arcLength(c, True)\n",
    "        approximation = cv2.approxPolyDP(c, 0.05*perimeter, True)\n",
    "        if len(approximation) == 4: # Contures with 4 corners\n",
    "            screen_countour = approximation\n",
    "            cv2.drawContours(copy3, [screen_countour], -1, (0, 255, 0), 3)\n",
    "            #cv2.imshow(\"passed\", copy3)\n",
    "            #cv2.waitKey()\n",
    "            \n",
    "            #if not is_rectangle(approximation): continue\n",
    "            if countour_is_whole_image(screen_countour, copied_image): continue \n",
    "            #if is_vertical_countour(screen_countour): continue\n",
    "            break\n",
    "\n",
    "    cv2.drawContours(copied_image, [screen_countour], -1, (0, 255, 0), 3)\n",
    "    return copied_image\n",
    "    \n",
    "    \n",
    "def find_countour(original_image, preprocessed_image, image_name, color_tuple=(0,255,0)):\n",
    "    countour, _ = cv2.findContours(preprocessed_image.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    resized = resize(original_image)\n",
    "    cropped = crop(resized)\n",
    "    cropped_duplicate = cropped.copy()\n",
    "    \n",
    "    cv2.drawContours(cropped_duplicate, countour, -1, color_tuple, thickness=3)\n",
    "    cv2.imshow(\"All countours\", cropped_duplicate)\n",
    "    #cv2.imwrite('./all_countours_'+str(image_name), cropped_duplicate)\n",
    "    cv2.waitKey()\n",
    "    \n",
    "    return find_license_plate(cropped.copy(), countour, image_name, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Run algorithm\n",
    "\n",
    "I'll use the premade methods from previous steps in preprocessing and locate_license_plate to locate the license plate in image \"car1.jpg\".\n",
    "\n",
    "#### Preprocessing\n",
    "Doing it this way makes it easy to see and change each step to my need. I could easily add morphing or shadow removal to the preprocessing, and change the order of each step. \n",
    "\n",
    "##### Steps in preprocessing for car1\n",
    "* Convert to grayscale \n",
    "* Resizing and cropping\n",
    "    * Working with the images for a long time, I came to the conclusion that on a general basis all images of license plates will have noise close to the image boundary, and that the license plate would almost always be located in the middle of the image, or in the bottom low part. \n",
    "    * Cropping the image based on this, removes a lot of uninteresting parts from the image that we know for a fact is not the license plate. You could also argue that an image with the license plate close to the image boundaries is a bad sample.\n",
    "* Blur and Threshold \n",
    "    * Because this image has quite good lightning and a clear difference in color between car and license plate, the threshold work good for car1. The TOZERO threshold gets the job done here, but BINARY is also an option.\n",
    "\n",
    "#### Locate_license_plate\n",
    "I found that thresholding worked well for some cases, while edge detector was suitable for other images. Therefore the method was divided into either using edge detector or thresholding. Using the two together gave me overall bad results.\n",
    "\n",
    "##### Steps in license plate locating for car1\n",
    "* Blur and Threshold \n",
    "    * Because this image has quite good lightning and a clear difference in color between car and license plate, the threshold work good for car1. The TOZERO threshold gets the job done here, but BINARY is also an option.\n",
    "* Finding countours\n",
    "    * I got really good results with using the basic countour finder. Using the convex hull also gave me basically the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    gray = grayscaled(image)\n",
    "    resized = resize(gray)\n",
    "    cropped = crop(resized)\n",
    "    #no_shadows = remove_shadows(cropped)\n",
    "    return cropped\n",
    "\n",
    "\n",
    "def locate_license_plate(image_name, edge=False):\n",
    "    image = import_image(image_name)\n",
    "    preprocessed_image = preprocessing(image)\n",
    "    \n",
    "    cv2.imshow(\"Cropped image\", preprocessed_image)\n",
    "    cv2.imwrite('./preprocessed_'+str(image_name), preprocessed_image)\n",
    "    cv2.waitKey()\n",
    "    \n",
    "    if edge:\n",
    "        edges = edge_detector(preprocessed_image)\n",
    "        cv2.imshow(\"Edge detector results\", edges)\n",
    "        #cv2.imwrite('./edges_'+str(image_name), edges)\n",
    "        cv2.waitKey()\n",
    "        countours = find_countour(image, edges, image_name)\n",
    "    else:\n",
    "        blurred = blur(preprocessed_image)\n",
    "        thresh = threshold(blurred)\n",
    "        cv2.imshow(\"Thresholded image\", thresh)\n",
    "        cv2.imwrite('./thresholded_'+str(image_name), thresh)\n",
    "        cv2.waitKey()\n",
    "        countours = find_countour(image, thresh, image_name)\n",
    "        \n",
    "    cv2.imshow(\"Final image with plate detected\", countours)\n",
    "    #cv2.imwrite('./result_'+str(image_name), countours)\n",
    "    cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Original image\n",
    "<img src=\"car1.jpg\" width=\"500\">\n",
    "\n",
    "### Preprocessed image\n",
    "Here we see that the image is cropped and we have removed parts of the picture that is not interesting for our task, like the Maserati logo etc.\n",
    "<img src=\"preprocessed_car1.jpg\" width=\"500\">\n",
    "\n",
    "### Thresholded image\n",
    "After blurring and using TOZERO threshold, it is significantly easier to detect the license plate\n",
    "<img src=\"thresholded_car1.jpg\" width=\"500\">\n",
    "\n",
    "### All countours\n",
    "Here is a representation of all the countours the algorithm found in the image\n",
    "<img src=\"all_countours_car1.jpg\" width=\"500\">\n",
    "\n",
    "### Final result\n",
    "The final result is shown with the best fitting approximated countour\n",
    "<img src=\"result_car1.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on the other cars\n",
    "\n",
    "The same algorithm is now performed on all the other images.\n",
    "It turns out this detects three cars in total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = ['car1.jpg', 'car2.jpg', 'car3.jpg', 'car4.jpg', 'car5.jpg', 'car6.jpg', 'car7.png', 'car8.jpg']\n",
    "\n",
    "for car in cars:\n",
    "    locate_license_plate(car)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Including car 1, this algorithm detects car2 and car4 as well.\n",
    "\n",
    "\n",
    "### Original image\n",
    "Success\n",
    "<img src=\"car2.jpg\" width=\"300\"> \n",
    "<img src=\"car3.jpg\" width=\"300\"> \n",
    "<img src=\"car4.jpg\" width=\"300\">\n",
    "<img src=\"car5.jpg\" width=\"300\">\n",
    "<img src=\"car6.jpg\" width=\"300\"> \n",
    "<img src=\"car7.png\" width=\"300\"> \n",
    "<img src=\"car8.jpg\" width=\"300\"> \n",
    "\n",
    "\n",
    "\n",
    "### Final result\n",
    "Success\n",
    "<img src=\"result_car2.jpg\" width=\"300\">\n",
    "Fail\n",
    "<img src=\"result_car3.jpg\" width=\"300\">\n",
    "Success\n",
    "<img src=\"result_car4.jpg\" width=\"300\">\n",
    "Fail\n",
    "<img src=\"result_car5.jpg\" width=\"300\">\n",
    "Fail\n",
    "<img src=\"result_car6.jpg\" width=\"300\">\n",
    "Fail\n",
    "<img src=\"result_car7.png\" width=\"300\">\n",
    "Fail\n",
    "<img src=\"result_car8.jpg\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out other methods \n",
    "\n",
    "By changing the algorithm, I can obtain better results for some cars.\n",
    "For car 6 and car 7, combining the `remove_shadow` using the **Canny edge detector** is the way to go.\n",
    "\n",
    "The `remove_shadow` step in now included after the image is cropped, like so:\n",
    "```python\n",
    "def preprocessing(image):\n",
    "    gray = grayscaled(image)\n",
    "    resized = resize(gray)\n",
    "    cropped = crop(resized)\n",
    "    no_shadows = remove_shadows(cropped) # The change\n",
    "    return no_shadows\n",
    "```\n",
    "\n",
    "#### The other cars\n",
    "Provided the methods I've implemented, I've unsuccessfully managed to detect the license plate for the other cars: car3, car5 and car8. See more in discussion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "locate_license_plate('car1.jpg')\n",
    "#locate_license_plate('car7.png', edge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results car 6 and car 7\n",
    "Result from the edge detector\n",
    "<img src=\"edges_car6.jpg\" width=\"400\">\n",
    "<img src=\"edges_car7.png\" width=\"400\">\n",
    "Final result\n",
    "<img src=\"edges_result_car6.jpg\" width=\"400\">\n",
    "<img src=\"edges_result_car7.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "\n",
    "## Results\n",
    "This is not a general (enough) method for detecting all license plates out there. I implemented the techniques we learned and discussed in class, but there is room for improvement. You could always keep tweeking some parameters like kernel size or epsilon to gain better results, but I felt applying the different processing methods and see what they did was more educational than finding the perfect sweetspot for some values and watch how that affected the overall result.\n",
    "\n",
    "There were many trials and errors, and in the end the simple solution with cropping, blurring and threshold was the one giving best results for most pictures at a time.\n",
    "\n",
    "## Challenges with lisence plate detection\n",
    "Working with this assignment gives a good understanding to what kind of challenges there is in license plate detection.\n",
    "\n",
    "**Colors on signs:**\n",
    "Out of the eight images provided, there are many different signs. Firstly they come in different colors; white, yellow and black. Especially the black sign on a red/darker car is hard to work with. When the license plate is the same color as the car/background, thresholding will normally do no good. My method is therefor not very good for the red Ferrari (car5).\n",
    "\n",
    "**Lightning and shadows:**\n",
    "The reason I created a `remove_shadows` method was because it became clear that the shadows in the images was creating a lot of trouble. Like discussed in class, thresholding is a very good method if it is done in environment with **controlled illumination**, which is mostly not the case for these kind of pictures. The edge detector was not that good either on the images with a lot of shadows, like car3.\n",
    "\n",
    "**Size and resolution:** \n",
    "There is no guarantee that the samples are of high quality. The images provided here are all in different sizes, either closeups of the plate like car1 and car2, but also images with a lot of unimportat infomation. That is why I chose to resize and crop the images, and assume that all license plates will probably be located in the cropped area. While running my algorithm, the `find_countours` method detected the rear or front window as possible license plates, because they were rectangles. By cropping out the top of the car, you reduce the chance of this. \n",
    "\n",
    "## Alternative methods\n",
    "\n",
    "**Template matching:**\n",
    "An alternative method is template matching. I was long considering this as an alternative, but chose not to implement it for several reasons. First of all, I would have to choose one sample to match with. If that was a white license plate, it would be hard to detect the black one. Also the ratio of length and width of the license plates are varying in the samples given, and the images are all different sizes. I think template matching would be great if it was given that all plates were in one format.\n",
    "\n",
    "**Classification of plates:** Another method is to classify the images based on their characteristics, eg. all white plates are treated in some way, white yellow plates are treated in another way. That would prove for a more complex and probably better algorithm but also way more time consuming to create. \n",
    "\n",
    "**Enhance the countour algorithm:** I faced some problems with the countour algorithm. Eg. for car7, it found a countour around the license plate using my standard algorithm, but for some reason it was not considered an approximation with four corners. Understanding and tweeking the contour algorithm could prove better results as well. There were a lot of times when I think the preprocessing did a good job, but the countours were dissapointing. Another way could be to fill the top_n countours and paint that on the image, and then find the plates. Unfortunately, I did not find a good way to achieve this.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
